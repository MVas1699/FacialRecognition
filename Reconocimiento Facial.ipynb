{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b85ce5",
   "metadata": {},
   "source": [
    "# Reconocimiento Facial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb2b63",
   "metadata": {},
   "source": [
    "Código en Google Colab: https://colab.research.google.com/drive/1Ts_suIiKu7RqTKEgGUgo0XGb1gG_7Mnt?usp=sharing\n",
    "\n",
    "Repositorio en Github:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e0af9",
   "metadata": {},
   "source": [
    "## Ejemplo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a5afa",
   "metadata": {},
   "source": [
    "En este ejemplo, vamos a realizar un reconocimiento facial pero utilizando imágenes cargadas desde nuestra computadora, y no en tiempo real. Utilizaremos un dataset con imágenes de 3 famosos panameños: Ruben Blades, Román Torres y Erika Ender. Para validar que el modelo funciona correctamente, utilizaremos una imagen de cada uno que no se encuentre en el Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a9ea99",
   "metadata": {},
   "source": [
    "### Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importación de la librería OpenCV\n",
    "import cv2\n",
    "#importación de la librería os para leer carpetas y archivos\n",
    "import os\n",
    "#importar numpy para convertir listas de python en matrices numpy\n",
    "#Esto es necesario para el reconocimiento facial en Python\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c3926",
   "metadata": {},
   "source": [
    "### Asignación de etiquetas a cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8558a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#etiquetado de cada sujeto a los que evaluaremos con el reconocimiento facial. El primer espacio de este vector lo dejamos\n",
    "#siempre vacio\n",
    "subjects = [\"\", \"Ruben Blades\", \"Erika Ender\", \"Román Torres\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabff06b",
   "metadata": {},
   "source": [
    "Cada sujeto que vamos a reconocer equivaldría a una clase, viendolo desde el punto de vista de un modelo de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f0a63",
   "metadata": {},
   "source": [
    "### Detección del rostro utilizando CascadeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981a60d",
   "metadata": {},
   "source": [
    "Como bien vimos en la presentación, uno de los primeros pasos en el reconocimiento facial es la detección de la cara. Para detectar la cara, utilizaremos un clasificador llamado CascadeClassifier, que nos pedirá como argumento un modelo de detección ya entrenado. El enlace de descarga para descargar este modelo se encuentra en la siguiente casilla.\n",
    "\n",
    "Para que el clasificador pueda detectar la cara, necesita trabajar con imágenes en escala de grises, de igual manera se debe realizar como primer paso recorte de la ubicación del rostro dentrro de la imagen. En este fragmento de código se realiza la conversión de la imagen a escala de grises y se utilizan el cv2.CascadeClassifier mediante un modelo de detección de frontal de rostros, para realizar el recorte de la cara en la imagen. Este método devuelve el (x, y, width, height) de la zona en la cual se encuentra el rostro, para que pueda ser extraida utilizando OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7d9e4",
   "metadata": {},
   "source": [
    "Enlace de Descarga del Modelo de detección: \n",
    "haarCascade: https://drive.google.com/file/d/1TtVphkjlkpCQRrK7Tm1dzShfdCsScWhH/view?usp=sharing\n",
    "lbpCascade: https://drive.google.com/file/d/1fAg-1sSn7wpqQJkXObzkhRdW9ZrUBy1e/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e15ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para detectar la cara usando OpenCV\n",
    "def detect_face(img):\n",
    "    #convierte la imagen de prueba en una imagen en escala de grises, ya que el detector de rostros opencv trabaja con \n",
    "    #imágenes en escala de grises\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #cargamos el clasificador Cascade, utilizando OpenCV. Usaremos un archivo xml que contiene el algoritmo de\n",
    "    #detección del rostro ya entrenado para saber qué características extraer de la imagen para encontrar el rostro\n",
    "    #Usaremos el lbpcascade, que es un modelo más eficiente que sus equivalentes.\n",
    "    face_cascade = cv2.CascadeClassifier('opencv/lbpcascade_frontalface.xml')\n",
    "\n",
    "    #detectemos imágenes multiescala (algunas imágenes pueden estar más cerca de la cámara que otras)\n",
    "    #El resultado es la lista de caras encontradas\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "    \n",
    "    #si no se detectan caras, la condición hará que el programa retorne la imagen original\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #bajo el supuesto de que solo habrá una cara, se extraerá el área de la cara\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    gray = cv2.resize(gray[y:y+w, x:x+h],(224,224)) #se cambiará el tamaño de la cara recortada en un tamaño 224x224\n",
    "    \n",
    "    #devolverá solo la parte de la cara de la imagen\n",
    "    return gray, faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7adb635",
   "metadata": {},
   "source": [
    "### Localización de la cara y recorte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a544089",
   "metadata": {},
   "source": [
    "Para poder entrenar el modelo, necesitamos obtener las caras que vamos a detectar y recortar. Cuando ya estén recortadas, lo siguiente que se hará es colocar las etiquetas a cada rostro detectado. En resumidas cuentas, esa es el funcionamiento del siguiente fragmento de código. La función recorrerá el directorio que le enviemos como parámetro y obtendrá cada imagen a la que se le detectará la cara para posteriormente etiquetarla. Básicamente, preparará los datos para su posterior entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde236a",
   "metadata": {},
   "source": [
    "Enlace del dataset: https://drive.google.com/drive/folders/1C0-UxcGntsAxVgYbmIvzv6HoOf06M1TW?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta función leerá las imágenes de entrenamiento de todas las personas, detectará la cara de cada imagen\n",
    "#y retornará dos listas exactamente del mismo tamaño, una lista de caras y otra lista de etiquetas para cada cara\n",
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #------PASO-1--------\n",
    "    #obtener los directorios (un directorio para cada sujeto (clase)) en la carpeta de entrenamiento\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #lista para almacenar todas las caras del sujeto\n",
    "    faces = []\n",
    "    #lista para contener todas las etiquetas de la cara del sujeto\n",
    "    labels = []\n",
    "    \n",
    "    #mediante un ciclo repetitivo, buscaremos las carpetas dentro de nuestra carpeta raíz (training-data)\n",
    "    for dir_name in dirs:\n",
    "        \n",
    "        #las carpetas que contienen las caras de nuestros sujetos inician con la letra 's' por lo que\n",
    "        #debemos ignorar las carpetas que se encuentren dentro del directorio raíz si no inicia con la letra\n",
    "        #'s'\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "            \n",
    "        #------PASO-2--------\n",
    "        #extraer el número de etiqueta del sujeto de dir_name\n",
    "        #formato del directorio name = slabel\n",
    "        #, por lo que eliminar la letra 's' de dir_name nos dará una etiqueta\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        #construye la ruta del directorio que contiene imágenes para el tema actual\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        \n",
    "        #obtenemos los nombres de las imágenes que están dentro del directorio de los sujetos dados\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        #------PASO-3--------\n",
    "        #iremos a través de cada nombre de imagen, leeremos la imagen,\n",
    "        #detectaremos el rostro y agregaremos rostro a la lista de rostros\n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #ignoramos los archivos del sistema como .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            #creamos la ruta de la imagen\n",
    "            #ejemplo de una ruta de imagen = training-data/s1/1.jpg\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #leemos la imagen obtenida de la ruta\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            #desplegamos una ventana para que contenga las imágenes que se están obteniendo de la ruta\n",
    "            #una por una\n",
    "            cv2.imshow(\"Training on image...\", image)\n",
    "            cv2.waitKey(100)\n",
    "            \n",
    "            #detectamos la cara de cada imagen desplegada\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            #------Paso-4--------\n",
    "            #En este ejemplo, ignoraremos las caras no detectadas\n",
    "            if face is not None:\n",
    "                #añadimos la cara detectada a la lista de caras\n",
    "                faces.append(face)\n",
    "                #añadimos la etiqueta para esta cara\n",
    "                labels.append(label)\n",
    "            \n",
    "    cv2.destroyAllWindows() #Cerramos la ventana desplegada para mostrar las imágenes dentro de la ruta de entrenamiento\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa377da",
   "metadata": {},
   "source": [
    "Enviaremos a la función el parámetro, que en este caso es el nombre de la carpeta con el dataset. Puede variar en muchos casos esta ruta, dependiendo de donde tenemos almacenado el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeramente, prepararemos nuestros datos de entrenamiento\n",
    "#Los datos estarán en dos listas del mismo tamaño\n",
    "#una lista contrendrá todas las caras detectadas\n",
    "#y la otra lista contendrá las respectivas etiquetas para cada cara\n",
    "print(\"Preparing data...\")\n",
    "faces, labels = prepare_training_data(\"training-data\")\n",
    "print(\"Data prepared\")\n",
    "\n",
    "#imprimimos el total de caras y etiquetas encontradas\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d686ed",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68f68a",
   "metadata": {},
   "source": [
    "En este paso procedemos a instanciar el reconocedor y posteriormente se realiza el entrenamiento del mismo utilizando el método `train(faces-vector, labels-vector)` el cual recibe la lista de caras y etiquetas del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para usar el EigenFaceRecognizer  \n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "#Para utilizar el FisherFaceRecognizer \n",
    "face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "#Para usar el LBPHFaceRecognizer\n",
    "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#entrenamiento de nuestro modelo de reconocimiento facial utilizando las caras recortadas en la preparación del entrenamiento\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d849d8",
   "metadata": {},
   "source": [
    "Podemos también guardar nuestro modelo ya entrenado, para así maximizar y optimizar nuestro modelo a nivel de ejecución. Para esto usaremos el método save, que guardará en el formato que le indiquemos nuestro modelo entrenado. En este caso, guardaremos el modelo en formato yml. Podemos asignarle una carpeta o podemos almacenarlo en la misma ubicación de este mismo Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d169c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer.save('facialrecognitiontraining.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2d1c0",
   "metadata": {},
   "source": [
    "El siguiente fragmento de código muestra cómo crear un rectángulo sobre la zona donde tanto el detector Cascade como el algoritmo de reconocimiento encontró la cara de la persona, y escribirán la etiqueta que ha definido el detector que corresponde con el rostro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#función que dibuja un rectángulo sobre la cara de la persona \n",
    "#de acuerdo con las coordenadas (x,y)\n",
    "#y con el ancho y alto dados\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "#función que escribe un texto sobre la imagen dada\n",
    "#tomando las coordenadas (x, y). \n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c854d9",
   "metadata": {},
   "source": [
    "### Predicción "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf6e4d",
   "metadata": {},
   "source": [
    "Para la predicción, utilizaremos una función que tomará como entrada la imagen cargada. La función hará una copia de la imagen original para no afectarla y la enviará a la función `detect_face`, donde esta función tomará la imagen copiada, la transformará a escala de grises y obtendrá la zona donde se encuentra el rostro (mediante coordenadas x y y) y las comparará con las clases ya entrenadas en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta función reconoce a la persona en la imagen suministrada\n",
    "#y dibuja un rectángulo alrededor de la cara detectada con el nombre de la \n",
    "#persona \n",
    "def predict(test_img):\n",
    "    #hace una copia de la imagen, ya que no queremos cambiar la imagen original\n",
    "    img = test_img.copy()\n",
    "    #detectamos la cara en la imagen\n",
    "    face, rect = detect_face(img)\n",
    "\n",
    "    #predecimos a la persona de la imagen usando nuestro reconocedor de rostros\n",
    "    label= face_recognizer.predict(face)\n",
    "    #print(label[0])\n",
    "    #obtenemos el nombre de la etiqueta respectiva devuelta por el reconocedor de rostros\n",
    "    label_text = subjects[label[0]]\n",
    "    \n",
    "    #dibujamos el rectangulo alrededor de la cara detectada\n",
    "    draw_rectangle(img, rect)\n",
    "    #Insertamos el nombre de la persona reconocida\n",
    "    draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    return img #retornamos la imagen con el reconocimiento del rostro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f81f11",
   "metadata": {},
   "source": [
    "Posteriormente, enviaremos la o las imágenes que queremos probar para ver si nuestro modelo funciona correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3096a",
   "metadata": {},
   "source": [
    "Enlace de las imágenes para las pruebas: https://drive.google.com/drive/folders/1vEZbarLQzZgnHFgdDgsvPkiZwgKPsTkM?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting images...\")\n",
    "\n",
    "#Cargamos las imágenes de pruebas\n",
    "test_img1 = cv2.imread(\"test-data/test8.jpg\")\n",
    "test_img2 = cv2.imread(\"test-data/test17.jpg\")\n",
    "\n",
    "#hacemos una predicción\n",
    "predicted_img1 = predict(test_img1)\n",
    "predicted_img2 = predict(test_img2)\n",
    "print(\"Prediction complete\")\n",
    "\n",
    "#Desplegamos los resultados obtenidos para las imágenes de pruebas suministradas\n",
    "cv2.imshow('Sujeto1', predicted_img1)\n",
    "cv2.imshow('Sujeto2', predicted_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() #cerramos las ventanas desplegadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00b54b",
   "metadata": {},
   "source": [
    "## Ejemplo 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9bdb5",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, pudimos observar cómo funciona el reconocimiento facial a nivel de codificación, pero usando imágenes cargada desde la computadora. En este ejemplo, realizaremos una detección y reconocimiento facial en tiempo real, utilizando la cámara web de nuestra computadora. Usaremos un dataset con la cara del presentador y de otras personas, para que se muestre el reconocimiento de varias personas en tiempo real. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163c8b1",
   "metadata": {},
   "source": [
    "### Importación de Librerías y Etiquetado de Clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "#etiquetado de cada sujeto a los que evaluaremos con el reconocimiento facial. El primer espacio de este vector lo dejamos\n",
    "#siempre vacio\n",
    "subjects = [\"\", \"Ruben Blades\", \"Miguel Vasquez\", \"Román Torres\", \"Erika Ender\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6316e9",
   "metadata": {},
   "source": [
    "### Detección de la cara "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para detectar la cara usando OpenCV\n",
    "def detect_face(img):\n",
    "    #convierte la imagen de prueba en una imagen en escala de grises, ya que el detector de rostros opencv trabaja con \n",
    "    #imágenes en escala de grises\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #cargamos el clasificador Cascade, utilizando OpenCV. Usaremos un archivo xml que contiene el algoritmo de\n",
    "    #detección del rostro ya entrenado para saber qué características extraer de la imagen para encontrar el rostro\n",
    "    #Usaremos el lbpcascade, que es un modelo más eficiente que sus equivalentes.\n",
    "    face_cascade = cv2.CascadeClassifier('opencv/lbpcascade_frontalface.xml')\n",
    "\n",
    "    #detectemos imágenes multiescala (algunas imágenes pueden estar más cerca de la cámara que otras)\n",
    "    #El resultado es la lista de caras encontradas\n",
    "    \n",
    "    #PARÁMETROS A TOMAR EN CUENTA\n",
    "    #scaleFactor = Este valor debe ser mayor a 1, pero entre más cerca esta del 1\n",
    "    #Mayor tiempo toma para entrenar, pero así reconoce mejor a la persona\n",
    "    #minNeighbors = el valor de 3 esta bien, pero entre mayor es, menos reconocerá.\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.03, minNeighbors=3);\n",
    "    \n",
    "    #si no se detectan caras, la condición hará que el programa retorne la imagen original\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #bajo el supuesto de que solo habrá una cara, se extraerá el área de la cara\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    gray = cv2.resize(gray[y:y+w, x:x+h],(224,224)) #se cambiará el tamaño de la cara recortada en un tamaño 224x224\n",
    "    \n",
    "    #retornaremos solamente la parte de la cara de la imagen\n",
    "    return gray, faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cc9dc",
   "metadata": {},
   "source": [
    "### Extracción de caras del dataset y etiquetado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta función leerá las imágenes de entrenamiento de todas las personas, detectará la cara de cada imagen\n",
    "#y retornará dos listas exactamente del mismo tamaño, una lista de caras y otra lista de etiquetas para cada cara\n",
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #------PASO-1--------\n",
    "    #obtener los directorios (un directorio para cada sujeto (clase)) en la carpeta de entrenamiento\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #lista para almacenar todas las caras del sujeto\n",
    "    faces = []\n",
    "    #lista para contener todas las etiquetas de la cara del sujeto\n",
    "    labels = []\n",
    "    \n",
    "    #mediante un ciclo repetitivo, buscaremos las carpetas dentro de nuestra carpeta raíz (training-data-project)\n",
    "    for dir_name in dirs:\n",
    "        \n",
    "        #las carpetas que contienen las caras de nuestros sujetos inician con la letra 's' por lo que\n",
    "        #debemos ignorar las carpetas que se encuentren dentro del directorio raíz si no inicia con la letra\n",
    "        #'s'\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "            \n",
    "        #------PASO-2--------\n",
    "        #extraer el número de etiqueta del sujeto de dir_name\n",
    "        #formato del directorio name = slabel\n",
    "        #, por lo que eliminar la letra 's' de dir_name nos dará una etiqueta\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        #construye la ruta del directorio que contiene imágenes para el tema actual\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        \n",
    "        #obtenemos los nombres de las imágenes que están dentro del directorio de los sujetos dados\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        #------PASO-3--------\n",
    "        #iremos a través de cada nombre de imagen, leeremos la imagen,\n",
    "        #detectaremos el rostro y agregaremos rostro a la lista de rostros\n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #ignoramos los archivos del sistema como .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            ##creamos la ruta de la imagen\n",
    "            #ejemplo de una ruta de imagen = training-data/s1/1.jpg\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #leemos la imagen obtenida de la ruta\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            #desplegamos una ventana para que contenga las imágenes que se están obteniendo de la ruta\n",
    "            #una por una \n",
    "            cv2.imshow(\"Training on image...\", image)\n",
    "            cv2.waitKey(100)\n",
    "            \n",
    "            #detectamos el rostro\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            #------Paso-4--------\n",
    "            #En este ejemplo, ignoraremos las caras no detectadas\n",
    "            if face is not None:\n",
    "                #añadimos la cara detectada a la lista de caras\n",
    "                faces.append(face)\n",
    "                ##añadimos la etiqueta de la cara detectada a la lista de etiquetas\n",
    "                labels.append(label)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66432b57",
   "metadata": {},
   "source": [
    "Enlace del dataset: https://drive.google.com/drive/folders/1HvldSIyEAhwfZ_HrDaeFM4PnalDGeIe3?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeramente, prepararemos nuestros datos de entrenamiento\n",
    "#Los datos estarán en dos listas del mismo tamaño\n",
    "#una lista contrendrá todas las caras detectadas\n",
    "#y la otra lista contendrá las respectivas etiquetas para cada cara\n",
    "print(\"Preparing data...\")\n",
    "faces, labels = prepare_training_data(\"training-data-project\")\n",
    "print(\"Data prepared\")\n",
    "\n",
    "#imprimimos el total de caras y etiquetas encontradas\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ee0ab",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb375547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para usar el EigenFaceRecognizer  \n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "#Para utilizar el FisherFaceRecognizer \n",
    "face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "#Para usar el LBPHFaceRecognizer\n",
    "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#entrenamiento de nuestro modelo de reconocimiento facial utilizando las caras recortadas en la preparación del entrenamiento\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66391644",
   "metadata": {},
   "source": [
    "### Captura de imagen usando la cámara web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f8b8f",
   "metadata": {},
   "source": [
    "A diferencia del ejemplo pasado, esta vez tomaremos la imagen en tiempo real. Para ello, usaremos un método de la librería cv2, que permite abrir una conexión con la cámara web o una cámara externa que se encuentre conectada a la computadora. El método se llama `VideoCapture` y su único parámetro es el número de cámara que vamos a utilizar. Si solo contamos con una cámara incorporada en nuestra computadora, su numeración es o 0 o 1. Para almacenar lo que se está viendo en tiempo real, usaremos el método `read()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ede04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del objeto VideoCapture para poder hacer uso de la cámara:\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('opencv/lbpcascade_frontalface.xml') #Lectura del archivo xml con el detector Cascade\n",
    "\n",
    "while True:\n",
    "    # Captura frame por frame desde la salida de video capturado por el objeto 'capture':\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Conversión de lo capturado en el frame a escala de grises para poder realizar la detección:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    aux_frame = gray_frame.copy()\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray_frame,1.1,4)  #Detección del rostro de la persona\n",
    "    \n",
    "    #Colocar un recuadro azul sobre la cara detectada\n",
    "    for(x,y,w,h) in faces:\n",
    "        rostro = aux_frame[y:y+h,x:x+w]\n",
    "        rostro = cv2.resize(rostro,(224,224))\n",
    "        result = face_recognizer.predict(rostro)\n",
    "        label_text = subjects[result[0]]\n",
    "        #cv2.putText(frame, label_text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "        \n",
    "        if result[1] < 6000:\n",
    "            #print('Valor: ',result[1])\n",
    "            cv2.putText(frame, label_text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame,(x,y),(x+w, y+h),(255,0,0),2)\n",
    "        else:\n",
    "            #print('Valor: ',result[1])\n",
    "            cv2.putText(frame, 'Desconocido', (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame,(x,y),(x+w, y+h),(0,0,255),2)\n",
    "        \n",
    "        #Colocar un texto sobre la imágen de salida (Se colocará en la esquina superior izquierda)\n",
    "    cv2.putText(img=frame,\n",
    "                text=\"Reconocimiento facial\",\n",
    "                org=(10, 40),\n",
    "                fontFace=2,\n",
    "                fontScale=1,\n",
    "                color=(255, 255, 255),\n",
    "                thickness=3)\n",
    "    \n",
    "    # Se muestra la imágen de salida en tiempo real\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    #Cerrar la imagen de salida a partir del clic sobre la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Cerrar las ventanas y borrar el contenido del objeto capture:\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509a857",
   "metadata": {},
   "source": [
    "Para deshabilitar la cámara y cerrar el detector, debemos presionar la tecla q. Si cerramos en la cruz, la cámara seguirá activa, ya que la conexión solo se cerrará cuando cliquemos la letra q. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
