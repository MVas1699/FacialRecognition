{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77c74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import serial #Librería para realizar la conexión con Arduino\n",
    "import time #Para manejar tiempos de espera\n",
    "\n",
    "#there is no label 0 in our training data so subject name for index/label 0 is empty\n",
    "subjects = [\"\", \"Javier Martinez\", \"Miguel Vasquez\", \"Carlos Villa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefa71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to detect face using OpenCV\n",
    "def detect_face(img):\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #load OpenCV face detector, I am using LBP which is fast\n",
    "    #there is also a more accurate but slow Haar classifier\n",
    "    face_cascade = cv2.CascadeClassifier('opencv/lbpcascade_frontalface.xml')\n",
    "\n",
    "    #let's detect multiscale (some images may be closer to camera than others) images\n",
    "    #result is a list of faces\n",
    "    \n",
    "    #PARÁMETROS A TOMAR EN CUENTA\n",
    "    #scaleFactor = Este valor debe ser mayor a 1, pero entre más cerca esta del 1\n",
    "    #Mayor tiempo toma para entrenar, pero así reconoce mejor a la persona\n",
    "    #minNeighbors = Yo creo que el valor de 3 esta bien, pero entre mayor es, menos reconocerá.\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.03, minNeighbors=3);\n",
    "    \n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    gray = cv2.resize(gray[y:y+w, x:x+h],(224,224))\n",
    "    \n",
    "    #return only the face part of the image\n",
    "    return gray, faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e5e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will read all persons' training images, detect face from each image\n",
    "#and will return two lists of exactly same size, one list \n",
    "# of faces and another list of labels for each face\n",
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #------STEP-1--------\n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #list to hold all subject faces\n",
    "    faces = []\n",
    "    #list to hold labels for all subjects\n",
    "    labels = []\n",
    "    \n",
    "    #let's go through each directory and read images within it\n",
    "    for dir_name in dirs:\n",
    "        \n",
    "        #our subject directories start with letter 's' so\n",
    "        #ignore any non-relevant directories if any\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "            \n",
    "        #------STEP-2--------\n",
    "        #extract label number of subject from dir_name\n",
    "        #format of dir name = slabel\n",
    "        #, so removing letter 's' from dir_name will give us label\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        #build path of directory containin images for current subject subject\n",
    "        #sample subject_dir_path = \"training-data/s1\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        \n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        #------STEP-3--------\n",
    "        #go through each image name, read image, \n",
    "        #detect face and add face to list of faces\n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #ignore system files like .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            #build image path\n",
    "            #sample image path = training-data/s1/1.pgm\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #read image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            #display an image window to show the image \n",
    "            cv2.imshow(\"Training on image...\", image)\n",
    "            cv2.waitKey(100)\n",
    "            \n",
    "            #detect face\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            #------STEP-4--------\n",
    "            #for the purpose of this tutorial\n",
    "            #we will ignore faces that are not detected\n",
    "            if face is not None:\n",
    "                #add face to list of faces\n",
    "                faces.append(face)\n",
    "                #add label for this face\n",
    "                labels.append(label)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a80c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'training-data-project'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10448/2599815211.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#and other list will contain respective labels for each face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Preparing data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training-data-project\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data prepared\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10448/2456850038.py\u001b[0m in \u001b[0;36mprepare_training_data\u001b[1;34m(data_folder_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#------STEP-1--------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#get the directories (one directory for each subject) in data folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#list to hold all subject faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'training-data-project'"
     ]
    }
   ],
   "source": [
    "#let's first prepare our training data\n",
    "#data will be in two lists of same size\n",
    "#one list will contain all the faces\n",
    "#and other list will contain respective labels for each face\n",
    "print(\"Preparing data...\")\n",
    "faces, labels = prepare_training_data(\"training-data-project\")\n",
    "print(\"Data prepared\")\n",
    "\n",
    "#print total faces and labels\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb375547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or use EigenFaceRecognizer by replacing above line with \n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "#or use FisherFaceRecognizer by replacing above line with \n",
    "face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#train our face recognizer of our training faces\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "493ede04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del objeto VideoCapture para poder hacer uso de la cámara:\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "#Iniciar la conexión con Arduino\n",
    "ser = serial.Serial('COM3',9600,timeout=1)\n",
    "time.sleep(2)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('opencv/lbpcascade_frontalface.xml') #Lectura del archivo xml con el detector Cascade\n",
    "\n",
    "while True:\n",
    "    # Captura frame por frame desde la salida de video capturado por el objeto 'capture':\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Conversión de lo capturado en el frame a escala de grises para poder realizar la detección:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    aux_frame = gray_frame.copy()\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray_frame,1.1,4)  #Detección del rostro de la persona\n",
    "    \n",
    "    #Colocar un recuadro azul sobre la cara detectada\n",
    "    for(x,y,w,h) in faces:\n",
    "        rostro = aux_frame[y:y+h,x:x+w]\n",
    "        rostro = cv2.resize(rostro,(224,224))\n",
    "        result = face_recognizer.predict(rostro)\n",
    "        label_text = subjects[result[0]]\n",
    "        #cv2.putText(frame, label_text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "        \n",
    "        if result[1] < 6000:\n",
    "            #print('Valor: ',result[1])\n",
    "            cv2.putText(frame, label_text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame,(x,y),(x+w, y+h),(255,0,0),2)\n",
    "            ser.write(b'R') #Envía la letra D al monitor serial para así encender el LED verde y mostrar en la LCD el mensaje\n",
    "            \n",
    "        else:\n",
    "            #print('Valor: ',result[1])\n",
    "            cv2.putText(frame, 'Desconocido', (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame,(x,y),(x+w, y+h),(0,0,255),2)\n",
    "            ser.write(b'D') #Envía la letra D al monitor serial para así encender el LED rojo y mostrar en la LCD el mensaje\n",
    "        \n",
    "        #Colocar un texto sobre la imágen de salida (Se colocará en la esquina superior izquierda)\n",
    "    cv2.putText(img=frame,\n",
    "                text=\"Reconocimiento facial\",\n",
    "                org=(10, 40),\n",
    "                fontFace=2,\n",
    "                fontScale=1,\n",
    "                color=(255, 255, 255),\n",
    "                thickness=3)\n",
    "    \n",
    "    # Se muestra la imágen de salida en tiempo real\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    #Cerrar la imagen de salida a partir del clic sobre la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Cerrar las ventanas y borrar el contenido del objeto capture:\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66fa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
